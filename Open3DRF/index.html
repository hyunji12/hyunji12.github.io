<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space">
  <meta name="keywords" content="3D Open-vocabulary Segmentation, 3D Point Querying, 3D Supervision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Open3DRF</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./template/css/bulma.min.css">
  <link rel="stylesheet" href="./template/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./template/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./template/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./template/css/index.css">
  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./template/js/fontawesome.all.min.js"></script>
  <script src="./template/js/bulma-carousel.min.js"></script>
  <script src="./template/js/bulma-slider.min.js"></script>
  <script src="./template/js/index.js"></script>
  
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-half-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title"><p style="line-height:140%">Rethinking Open-Vocabulary Segmentation<br>of Radiance Fields in 3D Space</h2></p>
          <div class="is-size-5 publication-authors">
            <img src="./template/figures/undercon.png" width="7%" />
            </span>
            <br>
            <p style="font-size:18px">We're currently working on this page. Please check back soon.</p><hr></span>
            <span class="author-block"> <p style="font-size:23px">
              Hyunjee Lee&#42;, 
              Youngsik Yun&#42;, 
              Jeongmin Bae, 
              Seoha Kim, 
              Youngjung Uh</p>
            </span>
              <br>
              <p style="font-size:18px">* equal contribution</p></span>
              <span class="author-block">
                <p style="font-size:23px">Yonsei University</p></span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- ArXiv Link. -->
              <span class="link-block">
                <a target="_blank" href="https://arxiv.org/abs/2408.07416"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a target="_blank" href="https://github.com/hyunji12/Open3DRF/tree/main"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#ffffff" d="M339 314.9L175.4 32h161.2l163.6 282.9H339zm-137.5 23.6L120.9 480h310.5L512 338.5H201.5zM154.1 67.4L0 338.5 80.6 480 237 208.8 154.1 67.4z"/></svg>
                  </span>
                  <span>Data</span>
                </a>
              </span>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>
<br>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="container has-text-centered">
          <figure>
            <img src="./template/figures/Teaser.png" width="50%" />
          </figure>
          <p style="margin-bottom: 40px;margin-top: 40px;">
            Previous works segment 2D masks on rendered images to understand radiance fields. 
            Instead, we reformulate the task to segment 3D volumes. 
            Our approach greatly improves 3D and 2D understanding of radiance fields. 
        </p>
      </div> 
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
    <div class="hero-body">
      <div class="container is-max-desktop">
         <div class="container has-text-centered">
          <div class="columns vertical_center">
            <video poster="" autoplay controls muted loop playsinline height="100%">
              <source src="./template/figures/blue_dish_soap.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
</section>
<br>
<br> -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h3 class="title is-3">Abstract</h3>
            <p style="margin-bottom: 40px;margin-top: 40px;">
              Understanding the 3D semantics of a scene is a fundamental problem for various scenarios such as embodied agents.
              While NeRFs and 3DGS excel at novel-view synthesis, previous methods for understanding their semantics have been limited to incomplete 3D understanding: 
              their segmentation results are 2D masks and their supervision is anchored at 2D pixels.
              This paper <b>revisits the problem set to pursue a better 3D understanding of a scene modeled by NeRFs and 3DGS</b> as follows. 
              1) We directly supervise the 3D points to train the language embedding field. It achieves state-of-the-art accuracy without relying on multi-scale language embeddings. 
              2) We transfer the pre-trained language field to 3DGS, achieving the first real-time rendering speed without sacrificing training time or accuracy. 
              3) We introduce a 3D querying and evaluation protocol for assessing the reconstructed geometry and semantics together.
            </p>
        </div>
      </div>
    </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h3 class="title is-3">Method Overview</h3>
            <figure>
              <img src="./template/figures/overview.png"/>
            </figure>
            <p style="margin-bottom: 40px;margin-top: 40px;">
              We propose <b>3D segmentation</b> as a more practical problem setting, segmenting the 3D volume for a given text query.
              Then we propose <b>point-wise semantic loss to supervise the sampled point embeddings.</b>
              Furthermore, the learned language fields can be <b>transferred into 3DGS for faster rendering speeds.</b>
              Lastly, <b>our 3D evaluation protocol</b> measures the 3D segmentation performance both in reconstructed geometry and semantics.
            </p>
        </div>
      </div>
    </div>
</section>
<br>
<br>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="container has-text-centered">
        <h3 class="title is-3"> Quantitative Results</h3>
        <p style="margin-bottom: 40px;margin-top: 40px;">
          We compare quantitative results of 3D and 2D segmentation in Replica dataset, LERF dataset, and 3D-OVS. 
          <figure>
            <img src="./template/figures/quant.png"/>
          </figure>
        </p>
      </div> 
    </div>
  </div>
</section>
<br>
<br>
<br>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="container has-text-centered">
        <h3 class="title is-3"> 3D Segmentation Results</h3>
        <p style="margin-bottom: 40px;margin-top: 40px;">
          <b>Qualitative comparisons of 3D segmentation on the LERF and Replica datasets.</b>
          We show an exported mesh of 3D querying results for the given text query. 
          Unlike competitors, our method produces more clear boundaries in 3D segmentation results. 
          <figure>
            <img src="./template/figures/3d_seg.png"/>
          </figure>
        </p>
      </div> 
    </div>
  </div>
</section>
<br>
<br>
<br>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="container has-text-centered">
        <h3 class="title is-3"> 2D Segmentation Results</h3>
        <p style="margin-bottom: 40px;margin-top: 40px;">
          <b>Qualitative Comparisons of 2D Segmentation on LERF and 3D-OVS Dataset.</b>
          We show a heatmap of the similarity for the given text query. We dim the background except for the target object, for better visualization.
          Our method achieves accurate segmentation results in 2D compared to competitors.
          <figure>
            <img src="./template/figures/2d_seg.png"/>
          </figure>
        </p>
      </div> 
    </div>
  </div>
</section>
<br>
<br>
<br>

<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="container has-text-centered">
        <h3 class="title is-3"> 3D segmentation Results</h3>
        <p style="margin-bottom: 40px;margin-top: 40px;">
          We compare qualitative results of 3D segmentation <b>by exporting a mesh</b> using a Poisson algorithm 
          for the region obtained through 3D querying.
          
        </p>




        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-set1">
            <div class="columns vertical_center">
              <div class="column is-one-seconds">
                <div class="column">
                  <figure>
                    <video poster="" autoplay controls muted loop playsinline height="100%">
                      <source src="./template/figures/table.mp4" type="video/mp4">
                    </video>
                  </figure>
                </div>
              </div>
            </div>
          </div>
          
          <div class="item item-set2">
            <div class="columns vertical_center">
              <div class="column is-one-thirds">
                <div class="column">
                  <figure>
                    <video poster="" autoplay controls muted loop playsinline height="100%">
                      <source src="./template/figures/table.mp4" type="video/mp4">
                    </video>
                  </figure>
                </div>
              </div>
            </div>
          </div>
          
          <div class="item item-set3">
            <div class="columns vertical_center">
              <div class="column is-one-thirds">
                <div class="column">
                  <figure>
                    <video poster="" autoplay controls muted loop playsinline height="100%">
                      <source src="./template/figures/table.mp4" type="video/mp4">
                    </video>
                  </figure>
                </div>
              </div>
            </div>
          </div>
        </div> 
      </div>
  </div>
</section>
<br>
<br>
<br> -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h3 class="title is-3">Real-time Rendering with Ours-<i>3DGS</i></h3>
          <p style="margin-bottom: 40px;margin-top: 40px;">
            Our transferred 3DGS from the pre-trained language field achieves <b>the first real-time rendering speed</b> of segmentation, 
            <br>which is <b>27x faster</b> than the previous fastest method.
          </p>
          <figure>
            <img src="./template/figures/comp_cost.png"/>
          </figure>
        </div>
      </div>
    </div>
</section>
<br>
<br>
<br>

<section class="hero is-small">
  <div class="container is-max-desktop">
      <h4 class="title is-4" style="padding-left:30px; padding-top:30px"> Citation </h4>
          <pre id="codecell0">
          @misc{lee2024rethinkingopenvocabularysegmentationradiance,
          title={Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space}, 
          author={Hyunjee Lee and Youngsik Yun and Jeongmin Bae and Seoha Kim and Youngjung Uh},
          year={2024},
          eprint={2408.07416},
          archivePrefix={arXiv},
          primaryClass={cs.CV},
          url={https://arxiv.org/abs/2408.07416}, 
          } </pre>
  </div>
</section>

<br>
<br>
<br>
<br>
</body>
</html>